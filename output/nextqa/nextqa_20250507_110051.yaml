EVAL_MODEL_NAME: "gpt-4o-mini"

reasoning_mode: "st"    # langgraph

visible_frames:
  init_sec_interval: null
  init_interval_num: null
  min_interval: null
  min_sec_interval: 1
  subtitle_path: null

tool:
  tool_list:
    - "TemporalGrounding"
    - "TemporalQA"
    - "PatchZoomer"
    - "ImageGridQA"
    - "ImageQA"
    - "Summarizer"
    - "FrameSelector"
  temporal_model:
    llm_type: "phi3.5"
    weight_path: "/hf_home/Grounded-Video-LLM/"
    device: "cuda:7"
  image_qa:
    model_path: "liuhaotian/llava-v1.5-7b"
    batch_size: 10
    device: "cuda:6"
  image_grid_qa:
    vlm_gpt_model_name: "gpt-4o" 
    init_grid_size: 3
    save_path: null
    mode:  "by_visible_frames"  # "by_video_path"
    with_analysis: False
    with_subtitle: False
  temporal_grounding:
    min_sec_interval: 2
  temporal_qa:
    mode: "by_visible_frames"  # "by_video_path"
  patch_zoomer:
    vlm_gpt_model_name: "gpt-4o" 
    use_cache: True
    concurrent: True
    concurrent_thread_num: 16
    image_resize: False
    sys_prompt: null # "You are a helpful, creative, and smart assistant."
  summarizer:
    llm_model_name: "gpt-4o-mini"
    use_cache: True
    mode: "by_caption"         # by_caption, by_qa
  frame_selector:
    llm_model_name: "gpt-4o-mini"
  image_captioner:
    device: "cuda:1"
  video_qa:
    # model_path: "Qwen/Qwen2.5-VL-7B-Instruct"
    model_path: "Qwen/Qwen2.5-VL-3B-Instruct"
    # model_path: "/hf_home/hub/models--Qwen--Qwen2-VL-2B-Instruct/snapshots/895c3a49bc3fa70a340399125c650a463535e71c"
  video_qa_internvl:
    model_path: 'OpenGVLab/InternVL3-2B'
    num_segments: 256

mannual_cache_file: "cache/gpt35_cache_new_tool_8.pkl"
use_cache: False

dataset: "nextqa"
video_path_base: "/share_data/NExT-QA/NExTVideo"
# anno_path: "/share_data/NExT-QA/dataset/nextqa/val.csv"
anno_path: "/share_data/NExT-QA/dataset/nextqa/test_sampled_100.csv"
# video_path_base: "/home/fsq/video_agent/NExT-QA/NExTVideo"
# anno_path: "/home/fsq/video_agent/NExT-QA/dataset/nextqa/val.csv"
num_examples_to_run: 10
start_num: 0

output_path: "output/nextqa/"

recursion_limit: 20

try_num: 1

try_except_mode: False
to_txt: True