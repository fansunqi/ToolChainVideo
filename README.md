# ToolChainVideo


## Setup and Configuration ğŸ› ï¸

1. Clone the repository ğŸ“¦:
   ```python
   git clone git@github.com:fansunqi/ToolChainVideo.git
   cd ToolChainVideo
   ```
2. Create a virtual environment ğŸ§¹ and install the dependencies ğŸ§‘â€ğŸ³:
   ```python
   conda create -n tcv python=3.9
   conda activate tcv
   pip install -r requirements.txt
   ```
3. Set up your API key ğŸ—ï¸ in `config/*.yaml`:
     ```python
     openai:
       GPT_API_KEY: "put your openai api key here"
       PROXY: "put your openai base url here"
     ```

5. Download the checkpoints  and bulid related projectğŸ§©:

   - **download LLaVA for Image QA**
     
     git clone this [repo](https://github.com/haotian-liu/LLaVA), modify ```LLaVA/llava/eval/run_llava.py``` and install following instrutions.


## Tools

Thanks to the authors of these open-source projects for providing excellent projects.

- Object Tracker: 
    + YOLO by ultralytics: https://github.com/ultralytics/ultralytics
- Image Captioner: 
    + BLIP: https://huggingface.co/docs/transformers/model_doc/blip
- Image QA:
    + BLIP: https://huggingface.co/docs/transformers/model_doc/blip
    + LLaVA: https://github.com/haotian-liu/LLaVA
- Frame Selector

## NExT-QA è¯•éªŒ

ä¸‹è½½ NeXT-QA æ•°æ®ï¼š
```
git clone git@github.com:doc-doc/NExT-QA.git
```
specify your data path in ```config/nextqa.yaml```

è¿è¡ŒæŒ‡ä»¤ï¼š

```
python scripts/main.py
```

é»˜è®¤ä½¿ç”¨çš„ config æ˜¯ `config/nextqa.yaml`

è¯„æµ‹æŒ‡ä»¤ï¼š

```
python eval/eval_nextqa.py
```


(04.11 æ›´æ–°) æœ€æ–°çš„è¿è¡ŒæŒ‡ä»¤ï¼š

```
python main_new_tools.py
```

é»˜è®¤ä½¿ç”¨çš„ config æ˜¯ `config/nextqa_new_tool.yaml`

æœ€æ–°çš„è¯„æµ‹æŒ‡ä»¤ï¼š

```
python eval.py
```